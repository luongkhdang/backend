version: "3.8"

services:
  # Reader DB - PostgreSQL database with pgvector for storing transferred articles
  postgres:
    image: ankane/pgvector:latest
    container_name: reader-db
    environment:
      POSTGRES_DB: reader_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5433:5432" # Map to port 5433 externally to avoid conflicts with news-db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - reader_network

  # Article Transfer Service - Transfers articles from news-api to reader-db
  article-transfer:
    build:
      context: .
      dockerfile: Dockerfile
    image: article-transfer-app:latest
    container_name: article-transfer
    restart: "no"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      # Reader DB connection
      READER_DB_HOST: postgres # Use container name within Docker network
      READER_DB_PORT: 5432 # Internal port in Docker network
      READER_DB_NAME: reader_db
      READER_DB_USER: postgres
      READER_DB_PASSWORD: postgres
      # News API connection - just use service name, which will be resolved by Docker DNS
      NEWS_API_BASE_URL: http://news-api:8000
      # Processing settings
      MAX_WORKERS: 4 # Number of parallel workers for processing
      DB_UPDATE_BATCH_SIZE: 20 # Batch size for DB inserts in Step 1.4
      CHECKPOINT_INTERVAL_SECONDS: 60 # Interval for DB updates
      # Gemini API settings
      GEMINI_API_KEY: ${GEMINI_API_KEY:-YOUR_API_KEY_HERE}
      GEMINI_EMBEDDING_MODEL: ${GEMINI_EMBEDDING_MODEL:-models/text-embedding-004}
      GEMINI_EMBEDDING_TASK_TYPE: ${GEMINI_EMBEDDING_TASK_TYPE:-CLUSTERING}
      GEMINI_EMBEDDING_INPUT_TOKEN_LIMIT: ${GEMINI_EMBEDDING_INPUT_TOKEN_LIMIT:-2048}
      GEMINI_EMBEDDING_OUTPUT_DIMENSION: ${GEMINI_EMBEDDING_OUTPUT_DIMENSION:-768}
      GEMINI_EMBEDDING_RATE_LIMIT_PER_MINUTE: ${GEMINI_EMBEDDING_RATE_LIMIT_PER_MINUTE:-1500}
      # Python path for Google imports
      PYTHONPATH: /app
      # Debug flag for imports
      PYTHONDEBUG: "1"
      # Flash model settings
      GEMINI_FLASH_MODEL: ${GEMINI_FLASH_MODEL:-gemini-2.0-flash}
      GEMINI_INPUT_CONTEXT_WINDOW_TOKEN: ${GEMINI_INPUT_CONTEXT_WINDOW_TOKEN:-1048576}
      GEMINI_FLASH_OUTPUT_WINDOW_TOKEN: ${GEMINI_FLASH_OUTPUT_WINDOW_TOKEN:-8192}
      GEMINI_FLASH_RATE_LIMIT_PER_MINUTE: ${GEMINI_FLASH_RATE_LIMIT_PER_MINUTE:-15}
      GEMINI_FLASH_RATE_LIMIT_PER_DAY: ${GEMINI_FLASH_RATE_LIMIT_PER_DAY:-1500}
      # Local NLP Settings (Step 1.7)
      RUN_STEP_1_7: ${RUN_STEP_1_7:-true}
      LOCAL_NLP_MODEL: ${LOCAL_NLP_MODEL:-"facebook/bart-large-cnn"}
      MAX_SUMMARY_TOKENS: ${MAX_SUMMARY_TOKENS:-512}
      MIN_SUMMARY_TOKENS: ${MIN_SUMMARY_TOKENS:-150}
      # Chunking parameters for Step 1.7
      ARTICLE_TOKEN_CHUNK_THRESHOLD: ${ARTICLE_TOKEN_CHUNK_THRESHOLD:-2000}
      TARGET_CHUNK_TOKEN_SIZE: ${TARGET_CHUNK_TOKEN_SIZE:-1000}
      CHUNK_MAX_TOKENS: ${CHUNK_MAX_TOKENS:-300}
      CHUNK_MIN_TOKENS: ${CHUNK_MIN_TOKENS:-75}
      # Step 2: Clustering settings
      RUN_CLUSTERING_STEP: ${RUN_CLUSTERING_STEP:-true}
      MIN_CLUSTER_SIZE: ${MIN_CLUSTER_SIZE:-10}
      HOT_CLUSTER_THRESHOLD: ${HOT_CLUSTER_THRESHOLD:-20}
      INTERPRET_CLUSTERS: ${INTERPRET_CLUSTERS:-true}
      MAX_CLUSTERS_TO_INTERPRET: ${MAX_CLUSTERS_TO_INTERPRET:-10}
      CLUSTER_SAMPLE_SIZE: ${CLUSTER_SAMPLE_SIZE:-10}
      # Debugging options
      LOG_LEVEL: INFO
      # Polling interval
      POLLING_INTERVAL: 300
      WAIT_SECONDS: 10
      # Use skip-network-check to bypass Docker CLI checks
      FORCE_CONTINUE_ON_NETWORK_ERROR: "true"
    # Add the skip-network-check flag to avoid Docker introspection
    command: ["python", "src/main.py", "--workers", "4", "--skip-network-check"]
    volumes:
      - ./src:/app/src # Mount source code for easier development
      - ./logs:/app/logs # Mount logs directory for error reports
      - huggingface_cache:/root/.cache/huggingface # Mount cache volume for HuggingFace models
    networks:
      - reader_network
    dns:
      - 8.8.8.8
      - 8.8.4.4
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import requests; requests.get('http://postgres:5432')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # pgAdmin - Web interface for database management
  pgadmin:
    image: dpage/pgadmin4
    container_name: reader-pgadmin
    depends_on:
      postgres:
        condition: service_started
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@reader.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5051:80"
    restart: unless-stopped
    networks:
      - reader_network

  # Backend service for database setup and management
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: reader-backend
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      READER_DB_HOST: postgres # Use container name within Docker network
      READER_DB_PORT: 5432 # Internal port in Docker network
      READER_DB_NAME: reader_db
      READER_DB_USER: postgres
      READER_DB_PASSWORD: postgres
      # Gemini API settings (also pass to backend if needed for future use)
      GEMINI_API_KEY: ${GEMINI_API_KEY:-YOUR_API_KEY_HERE}
      GEMINI_EMBEDDING_MODEL: ${GEMINI_EMBEDDING_MODEL:-models/text-embedding-004}
      # Python path for Google imports
      PYTHONPATH: /app
      # Wait settings
      WAIT_FOR_DB: "true"
      WAIT_SECONDS: "10"
    volumes:
      - ./src:/app/src # Mount source code for easier development
    restart: unless-stopped
    networks:
      - reader_network
    command: ["python", "src/database/db_setup.py"]

# Define Docker networks
networks:
  reader_network:
    # This file now manages the creation of reader_network
    driver: bridge
    # Optionally specify the name if desired, otherwise it defaults based on directory
    name: reader_network

# Define persistent volumes
volumes:
  postgres_data: # Persistent volume for reader-db data
  huggingface_cache: # Persistent volume for Hugging Face models/cache
